---
format:
   revealjs:
     slide-number: true
     incremental: true
     footer: "&copy; 2024 Hibiki AI Limited, Eli Lilly and Company"
     view-distance: 100
     mobile-view-distance: 100
---

##

```{r, include = FALSE, echo = FALSE}
knitr::opts_chunk$set(
  cache = FALSE,
  comment = "#>",
  fig.width = 10, 
  fig.height = 5
)
```

<style>
.reveal .tiny {
  display: inline-block;
  font-size: 0.5em;
  line-height: 1.0em;
  vertical-align: top;
}
.reveal .medium {
  display: inline-block;
  font-size: 0.75em;
  line-height: 1.5em;
  vertical-align: top;
}
</style>

<center>
<br>
<h3>mirai and crew: next-generation async to supercharge Plumber, Shiny, and targets</h3>
<img src="./images/title.png" height="400px">
<br>
<h4>Charlie Gao and Will Landau</h4>
</center>

## Carrying the baton for R

<img src="./images/joe.png">

## What is (next generation) async?

. . .

<span style="color:darkgreen">Async is the ability to do multiple things at once</span>

. . .

<span style="color:darkgreen">And keep doing more of those things</span>

. . .


In many programming languages, async is treated as a 'first class' citizen

. . .

::: {.nonincremental}
- Rust has its 'fearless concurrency'
- Go has its Goroutines
- Javascript has its Promises
:::

. . .

<span style="color:blue">Javascript 'just works'<sup>TM</sup> in your web browser</span>

## Where we are now in R

. . .

<span style="color:darkgreen">Async is the ability to do multiple things at once</span>

<span style="color:darkgreen">And keep doing more of those things</span>

- {coro} splits up current execution, not true parallelism
- {callr} only for local parallelism, saves files to filesystem
- {future} relies on {parallelly} and blocks if tasks > workers

. . .

<span style="color:brown">Missing a 'first-class' async experience</span>

## Bringing first class async to R

. . .

<img src="./images/nng.png">

::: {.nonincremental}
- Nanomsg Next Gen (NNG) implements async in C
- Incredibly lightweight, brokerless messaging
:::
- {nanonext} brings NNG to R &nbsp;&nbsp;&nbsp; <img src="./images/nanonext.png" width="160" align="right">


## mirai

ミライ <img src="./images/mirai.png" width="160" align="right">

Minimalist Async Evaluation Framework for R

. . .

<span style="color:darkgreen">Async is the ability to do multiple things at once</span>

<span style="color:darkgreen">And keep doing more of those things</span>

- {mirai} uses {nanonext} to deliver 'first-class' async
- Connect thousands of parallel processes
- Launch millions of tasks <span style="color:darkgreen">all at once</span>
- Responsiveness: <span style="color:red">milli</span>seconds -> <span style="color:blue">micro</span>seconds

## The current generation of promises

A 'promising' object is used in Shiny ExtendedTask / Plumber:

- `future()` blocks the session if tasks > workers
- `future_promise()` has never exited 'experimental'
- Requires constant polling for resolution of each promise

::: {.r-stack}
![](./images/hula1.gif){.fragment}

![](./images/hula1.gif){.fragment}![](./images/hula1.gif){.fragment}![](./images/hula1.gif){.fragment}![](./images/hula1.gif){.fragment}
:::

## The next generation of promises

- `mirai()` is now a 'promising' object
- Native support for Shiny ExtendedTask / Plumber

:::: {.columns}
::: {.column width="50%"}
![](./images/wiredcon.gif){.fragment}
:::
::: {.column width="50%"}
- Event-driven & efficient
- Zero-latency
- Launch one million promises <span style="color:darkgreen">all at once</span>
:::
::::

## Extending mirai

<center>
<img src="./images/crew.png">
</center>

## Science demands heavy computing

<center>
<img src="./images/pipette.jpg" width=500>
</center>

::: {style="font-size:90%"}

* Bayesian methods help safety/efficacy decisions in clinical trials
* Each model could take hours to run
* 1000+ simulations to design a clinical trial

:::

## Too much work for one laptop

:::: {.columns}

::: {.column width="50%"}

![](./images/hpc1.jpg)

:::

::: {.column width="50%"}

![](./images/hpc2.jpg)

:::

::::

* Clinical trial simulations often need hundreds of computers
* Need distributed computing: e.g. SLURM clusters, AWS Batch
* Challenges: <b><span style="color:blue">access</span></b>, <b><span style="color:brown">overhead</span></b>, and <b><span style="color:darkGreen">cost</span></b>


## `crew` scales data science

![](./images/plugins.png)

1. `mirai` provides low-<b><span style="color:brown">overhead</span></b> interprocess communication
2. Auto-scaling reduces <b><span style="color:brown">overhead</span></b> and <b><span style="color:darkGreen">cost</span></b>
3. Plugins <b><span style="color:blue">access</span></b> big high-performance computing systems

## Low-<b><span style="color:brown">overhead</span></b> communication

![](./images/workers1.png)

## Low-<b><span style="color:brown">overhead</span></b> communication

![](./images/workers2.png)

## Low-<b><span style="color:brown">overhead</span></b> communication

![](./images/workers3.png)

## Low-<b><span style="color:brown">overhead</span></b> communication

![](./images/workers4.png)


## Auto-scaling reduces <b><span style="color:brown">overhead</span></b> & <b><span style="color:darkGreen">cost</span></b>

![](./images/autoscale1.png)

## Auto-scaling reduces <b><span style="color:brown">overhead</span></b> & <b><span style="color:darkGreen">cost</span></b>

![](./images/autoscale2.png)

## Auto-scaling reduces <b><span style="color:brown">overhead</span></b> & <b><span style="color:darkGreen">cost</span></b>

![](./images/autoscale3.png)

## Auto-scaling reduces <b><span style="color:brown">overhead</span></b> & <b><span style="color:darkGreen">cost</span></b>

![](./images/autoscale4.png)

## Auto-scaling reduces <b><span style="color:brown">overhead</span></b> & <b><span style="color:darkGreen">cost</span></b>

![](./images/autoscale5.png)

## Auto-scaling reduces <b><span style="color:brown">overhead</span></b> & <b><span style="color:darkGreen">cost</span></b>

![](./images/autoscale6.png)

## Simple controller interface

<br>

:::: {style="font-size:150%"}

```r
# New controller

controller <- crew_controller_local(
  workers = 2,
  seconds_idle = 10,
  tasks_max = Inf
)
```

::::

## Simple controller interface

<br>

:::: {style="font-size:150%"}

```r
# Submit a task.

controller$push(1 + 1)
```

::::

## Simple controller interface

<br>

:::: {style="font-size:150%"}

```r
# Get the result.

controller$pop()
```

::::

## AWS Batch plugin

:::: {.columns style="font-size:125%"}

::: {.column width="75%"}

<br>

```r
crew_controller_aws_batch(
  workers = 100,
  seconds_idle = 60,
  aws_batch_job_definition = "DEF",
  aws_batch_job_queue = "QUEUE"
)
```
:::

::: {.column width="25%"}

<img src="./images/crew.aws.batch.png">

:::

::::

<br>

* Write your own plugins: <https://wlandau.github.io/crew/articles/plugins.html>

## `crew` unblocks Shiny apps

:::: {.columns style="font-size:130%"}

```r
observeEvent(input$button, {
  replicate(1000, 
    controller$push(flip_coin(), ...) %...>%
      collect_flips(controller, ...)
  )
})
```

::::

![](./images/coin-flips.gif)

## `crew` accelerates `targets`

<br>

:::: {.columns style="font-size:115%"}

::: {.column width="75%"}

```r
#_targets.R file

tar_option_set(
  controller = crew_controller_aws_batch(
    workers = 100,
    seconds_idle = 120,
    aws_batch_job_definition = "DEF",
    aws_batch_job_queue = "QUEUE"
  )
)
```

:::

::: {.column width="25%"}

![](./images/targets.png)

:::

::::
